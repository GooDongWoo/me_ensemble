{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 모델 로드 및 전처리 등 실험과 상관 없는 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imagenet-1k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at data/imagenet/imagenet-1k/default/1.0.0/07900defe1ccf3404ea7e5e876a64ca41192f6c07406044771544ef1505831e8 (last modified on Fri Nov 15 11:12:13 2024).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7164e0864c05414b9d4cce8fd9cb3f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64efd208bfa4b3692abfec3d6727458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imagenet-1k couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at data/imagenet/imagenet-1k/default/1.0.0/07900defe1ccf3404ea7e5e876a64ca41192f6c07406044771544ef1505831e8 (last modified on Fri Nov 15 11:12:13 2024).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2142bde413749bc816ab8814b116559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be59c12e4074942ada078d8fad2f1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54779/2455132039.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_model.load_state_dict(torch.load(me_ptd_path))\n",
      "/tmp/ipykernel_54779/2455132039.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  new_model.load_state_dict(torch.load(me_ptd_path))  # Load your trained weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models,datasets\n",
    "from me_models import MultiExitViT\n",
    "from me_ResNet import MultiExitResNet\n",
    "from Dloaders import Dloaders\n",
    "####################################################################\n",
    "IMG_SIZE = 224\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset_name = {'cifar10':datasets.CIFAR10, 'cifar100':datasets.CIFAR100,'imagenet':None}\n",
    "dataset_outdim = {'cifar10':10, 'cifar100':100,'imagenet':1000}\n",
    "##############################################################\n",
    "################ 0. Hyperparameters ##########################\n",
    "##############################################################\n",
    "batch_size = 1024\n",
    "data_choice='imagenet'\n",
    "model_choice='vit' #vit or resnet\n",
    "mevit_isload=True\n",
    "me_ptd_path=f\"models/{model_choice}/{data_choice}/integrated_ee.pth\"\n",
    "backbone_path=f'models/{model_choice}/{data_choice}/{model_choice}_{data_choice}_backbone.pth'\n",
    "\n",
    "file_path = f'cache_result_{model_choice}_{data_choice}.pt'\n",
    "\n",
    "ee_list=[0,1,2,3,4,5,6,7,8,9]#exit list ex) [0,1,2,3,4,5,6,7,8,9]\n",
    "exit_loss_weights=[1,1,1,1,1,1,1,1,1,1,1]#exit마다 가중치\n",
    "exit_num=11\n",
    "##############################################################\n",
    "dloaders=Dloaders(data_choice=data_choice,batch_size=batch_size,IMG_SIZE=IMG_SIZE)\n",
    "train_loader,test_loader = dloaders.get_loaders()\n",
    "\n",
    "# Load the pretrained ViT model from the saved file\n",
    "if model_choice == 'vit':\n",
    "    # Load the pretrained ViT model from the saved file\n",
    "    ptd_model = models.vit_b_16(weights=None)\n",
    "    ptd_model.heads.head = nn.Linear(ptd_model.heads.head.in_features, dataset_outdim[data_choice])  # Ensure output matches the number of classes\n",
    "    # Load model weights\n",
    "    new_model = MultiExitViT(base_model=ptd_model,num_classes=dataset_outdim[data_choice])\n",
    "elif model_choice == 'resnet':\n",
    "    # Load the pretrained ResNet model from the saved file\n",
    "    ptd_model = models.resnet101()\n",
    "    ptd_model.fc = nn.Linear(ptd_model.fc.in_features, dataset_outdim[data_choice])\n",
    "    # Load model weights\n",
    "    new_model = MultiExitResNet(base_model=ptd_model,num_classes=dataset_outdim[data_choice])    \n",
    "\n",
    "new_model.load_state_dict(torch.load(me_ptd_path))\n",
    "new_model.to(device)\n",
    "\n",
    "# Assume a pretrained model (replace with your own model)\n",
    "new_model.load_state_dict(torch.load(me_ptd_path))  # Load your trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MEVIT의 각 출구들에서의 Precision을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_cifar10_acc = [64.47, 72.24, 81.45, 84.25, 86.01, 90.24, 92.6, 94.31, 95.77, 95.08, 97.52]\n",
    "resnet_cifar100_acc = [37.8, 44.83, 60.08, 67.39, 72.1, 74.34, 77.32, 79.9, 80.94, 83.05, 86.24]\n",
    "resnet_imagenet_acc = [28.278, 35.742, 51.206, 54.662, 60.53, 63.732, 67.158, 70.394, 73.672, 79.374, 80.888]\n",
    "vit_cifar10_acc = [72.76, 80.35, 85.8, 89.42, 91.98, 93.12, 94.94, 96.44, 96.95, 97.35, 97.63]\n",
    "vit_cifar100_acc = [48.21, 59.63, 67.93, 73.31, 77.9, 80.8, 83.71, 85.33, 86.61, 87.04, 87.75]\n",
    "vit_imagenet_acc = [34.76, 42.65, 51.82, 57.76, 62.19, 65.5, 69.29, 72.3, 75.3, 77.6, 81.06]\n",
    "\n",
    "resnet_cifar10_flops = [1412860928, 2076990464, 2890800128, 3550413824, 4210027520, 4869641216, 5529254912, 6188868608, 6848482304, 7661519360, 7880637952]\n",
    "resnet_cifar100_flops = [1412907008, 2077036544, 2890892288, 3550505984, 4210119680, 4869733376, 5529347072, 6188960768, 6848574464, 7661703680, 7880822272]\n",
    "resnet_imagenet_flops = [1413367808, 2077497344, 2891813888, 3551427584, 4211041280, 4870654976, 5530268672, 6189882368, 6849496064, 7663546880, 7882665472]\n",
    "vit_cifar10_flops = [2908083456, 4303940352, 5699797248, 7095654144, 8491511040, 9887367936, 11283224832, 12679081728, 14074938624, 15470795520, 16866652416]\n",
    "vit_cifar100_flops = [2908152576, 4304009472, 5699866368, 7095723264, 8491580160, 9887437056, 11283293952, 12679150848, 14075007744, 15470864640, 16866721536]\n",
    "vit_imagenet_flops= [2908843776, 4304700672, 5700557568, 7096414464, 8492271360, 9888128256, 11283985152, 12679842048, 14075698944, 15471555840, 16867412736]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MEVIT의 각 출구들까지의 FLOPs 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 9 time(s)\n",
      "Unsupported operator aten::add encountered 5 time(s)\n",
      "Unsupported operator aten::div encountered 2 time(s)\n",
      "Unsupported operator aten::unflatten encountered 2 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 2 time(s)\n",
      "Unsupported operator aten::gelu encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1, base_model.encoder.layers.encoder_layer_1.dropout, base_model.encoder.layers.encoder_layer_1.ln_1, base_model.encoder.layers.encoder_layer_1.ln_2, base_model.encoder.layers.encoder_layer_1.mlp, base_model.encoder.layers.encoder_layer_1.mlp.0, base_model.encoder.layers.encoder_layer_1.mlp.1, base_model.encoder.layers.encoder_layer_1.mlp.2, base_model.encoder.layers.encoder_layer_1.mlp.3, base_model.encoder.layers.encoder_layer_1.mlp.4, base_model.encoder.layers.encoder_layer_1.self_attention, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2, base_model.encoder.layers.encoder_layer_2.dropout, base_model.encoder.layers.encoder_layer_2.ln_1, base_model.encoder.layers.encoder_layer_2.ln_2, base_model.encoder.layers.encoder_layer_2.mlp, base_model.encoder.layers.encoder_layer_2.mlp.0, base_model.encoder.layers.encoder_layer_2.mlp.1, base_model.encoder.layers.encoder_layer_2.mlp.2, base_model.encoder.layers.encoder_layer_2.mlp.3, base_model.encoder.layers.encoder_layer_2.mlp.4, base_model.encoder.layers.encoder_layer_2.self_attention, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3, base_model.encoder.layers.encoder_layer_3.dropout, base_model.encoder.layers.encoder_layer_3.ln_1, base_model.encoder.layers.encoder_layer_3.ln_2, base_model.encoder.layers.encoder_layer_3.mlp, base_model.encoder.layers.encoder_layer_3.mlp.0, base_model.encoder.layers.encoder_layer_3.mlp.1, base_model.encoder.layers.encoder_layer_3.mlp.2, base_model.encoder.layers.encoder_layer_3.mlp.3, base_model.encoder.layers.encoder_layer_3.mlp.4, base_model.encoder.layers.encoder_layer_3.self_attention, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4, base_model.encoder.layers.encoder_layer_4.dropout, base_model.encoder.layers.encoder_layer_4.ln_1, base_model.encoder.layers.encoder_layer_4.ln_2, base_model.encoder.layers.encoder_layer_4.mlp, base_model.encoder.layers.encoder_layer_4.mlp.0, base_model.encoder.layers.encoder_layer_4.mlp.1, base_model.encoder.layers.encoder_layer_4.mlp.2, base_model.encoder.layers.encoder_layer_4.mlp.3, base_model.encoder.layers.encoder_layer_4.mlp.4, base_model.encoder.layers.encoder_layer_4.self_attention, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5, base_model.encoder.layers.encoder_layer_5.dropout, base_model.encoder.layers.encoder_layer_5.ln_1, base_model.encoder.layers.encoder_layer_5.ln_2, base_model.encoder.layers.encoder_layer_5.mlp, base_model.encoder.layers.encoder_layer_5.mlp.0, base_model.encoder.layers.encoder_layer_5.mlp.1, base_model.encoder.layers.encoder_layer_5.mlp.2, base_model.encoder.layers.encoder_layer_5.mlp.3, base_model.encoder.layers.encoder_layer_5.mlp.4, base_model.encoder.layers.encoder_layer_5.self_attention, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0.0.self_attention.out_proj, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 13 time(s)\n",
      "Unsupported operator aten::add encountered 7 time(s)\n",
      "Unsupported operator aten::div encountered 3 time(s)\n",
      "Unsupported operator aten::unflatten encountered 3 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 3 time(s)\n",
      "Unsupported operator aten::gelu encountered 3 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2, base_model.encoder.layers.encoder_layer_2.dropout, base_model.encoder.layers.encoder_layer_2.ln_1, base_model.encoder.layers.encoder_layer_2.ln_2, base_model.encoder.layers.encoder_layer_2.mlp, base_model.encoder.layers.encoder_layer_2.mlp.0, base_model.encoder.layers.encoder_layer_2.mlp.1, base_model.encoder.layers.encoder_layer_2.mlp.2, base_model.encoder.layers.encoder_layer_2.mlp.3, base_model.encoder.layers.encoder_layer_2.mlp.4, base_model.encoder.layers.encoder_layer_2.self_attention, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3, base_model.encoder.layers.encoder_layer_3.dropout, base_model.encoder.layers.encoder_layer_3.ln_1, base_model.encoder.layers.encoder_layer_3.ln_2, base_model.encoder.layers.encoder_layer_3.mlp, base_model.encoder.layers.encoder_layer_3.mlp.0, base_model.encoder.layers.encoder_layer_3.mlp.1, base_model.encoder.layers.encoder_layer_3.mlp.2, base_model.encoder.layers.encoder_layer_3.mlp.3, base_model.encoder.layers.encoder_layer_3.mlp.4, base_model.encoder.layers.encoder_layer_3.self_attention, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4, base_model.encoder.layers.encoder_layer_4.dropout, base_model.encoder.layers.encoder_layer_4.ln_1, base_model.encoder.layers.encoder_layer_4.ln_2, base_model.encoder.layers.encoder_layer_4.mlp, base_model.encoder.layers.encoder_layer_4.mlp.0, base_model.encoder.layers.encoder_layer_4.mlp.1, base_model.encoder.layers.encoder_layer_4.mlp.2, base_model.encoder.layers.encoder_layer_4.mlp.3, base_model.encoder.layers.encoder_layer_4.mlp.4, base_model.encoder.layers.encoder_layer_4.self_attention, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5, base_model.encoder.layers.encoder_layer_5.dropout, base_model.encoder.layers.encoder_layer_5.ln_1, base_model.encoder.layers.encoder_layer_5.ln_2, base_model.encoder.layers.encoder_layer_5.mlp, base_model.encoder.layers.encoder_layer_5.mlp.0, base_model.encoder.layers.encoder_layer_5.mlp.1, base_model.encoder.layers.encoder_layer_5.mlp.2, base_model.encoder.layers.encoder_layer_5.mlp.3, base_model.encoder.layers.encoder_layer_5.mlp.4, base_model.encoder.layers.encoder_layer_5.self_attention, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1.0.self_attention.out_proj, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 17 time(s)\n",
      "Unsupported operator aten::add encountered 9 time(s)\n",
      "Unsupported operator aten::div encountered 4 time(s)\n",
      "Unsupported operator aten::unflatten encountered 4 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 4 time(s)\n",
      "Unsupported operator aten::gelu encountered 4 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3, base_model.encoder.layers.encoder_layer_3.dropout, base_model.encoder.layers.encoder_layer_3.ln_1, base_model.encoder.layers.encoder_layer_3.ln_2, base_model.encoder.layers.encoder_layer_3.mlp, base_model.encoder.layers.encoder_layer_3.mlp.0, base_model.encoder.layers.encoder_layer_3.mlp.1, base_model.encoder.layers.encoder_layer_3.mlp.2, base_model.encoder.layers.encoder_layer_3.mlp.3, base_model.encoder.layers.encoder_layer_3.mlp.4, base_model.encoder.layers.encoder_layer_3.self_attention, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4, base_model.encoder.layers.encoder_layer_4.dropout, base_model.encoder.layers.encoder_layer_4.ln_1, base_model.encoder.layers.encoder_layer_4.ln_2, base_model.encoder.layers.encoder_layer_4.mlp, base_model.encoder.layers.encoder_layer_4.mlp.0, base_model.encoder.layers.encoder_layer_4.mlp.1, base_model.encoder.layers.encoder_layer_4.mlp.2, base_model.encoder.layers.encoder_layer_4.mlp.3, base_model.encoder.layers.encoder_layer_4.mlp.4, base_model.encoder.layers.encoder_layer_4.self_attention, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5, base_model.encoder.layers.encoder_layer_5.dropout, base_model.encoder.layers.encoder_layer_5.ln_1, base_model.encoder.layers.encoder_layer_5.ln_2, base_model.encoder.layers.encoder_layer_5.mlp, base_model.encoder.layers.encoder_layer_5.mlp.0, base_model.encoder.layers.encoder_layer_5.mlp.1, base_model.encoder.layers.encoder_layer_5.mlp.2, base_model.encoder.layers.encoder_layer_5.mlp.3, base_model.encoder.layers.encoder_layer_5.mlp.4, base_model.encoder.layers.encoder_layer_5.self_attention, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2.0.self_attention.out_proj, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 21 time(s)\n",
      "Unsupported operator aten::add encountered 11 time(s)\n",
      "Unsupported operator aten::div encountered 5 time(s)\n",
      "Unsupported operator aten::unflatten encountered 5 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 5 time(s)\n",
      "Unsupported operator aten::gelu encountered 5 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4, base_model.encoder.layers.encoder_layer_4.dropout, base_model.encoder.layers.encoder_layer_4.ln_1, base_model.encoder.layers.encoder_layer_4.ln_2, base_model.encoder.layers.encoder_layer_4.mlp, base_model.encoder.layers.encoder_layer_4.mlp.0, base_model.encoder.layers.encoder_layer_4.mlp.1, base_model.encoder.layers.encoder_layer_4.mlp.2, base_model.encoder.layers.encoder_layer_4.mlp.3, base_model.encoder.layers.encoder_layer_4.mlp.4, base_model.encoder.layers.encoder_layer_4.self_attention, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5, base_model.encoder.layers.encoder_layer_5.dropout, base_model.encoder.layers.encoder_layer_5.ln_1, base_model.encoder.layers.encoder_layer_5.ln_2, base_model.encoder.layers.encoder_layer_5.mlp, base_model.encoder.layers.encoder_layer_5.mlp.0, base_model.encoder.layers.encoder_layer_5.mlp.1, base_model.encoder.layers.encoder_layer_5.mlp.2, base_model.encoder.layers.encoder_layer_5.mlp.3, base_model.encoder.layers.encoder_layer_5.mlp.4, base_model.encoder.layers.encoder_layer_5.self_attention, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3.0.self_attention.out_proj, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 25 time(s)\n",
      "Unsupported operator aten::add encountered 13 time(s)\n",
      "Unsupported operator aten::div encountered 6 time(s)\n",
      "Unsupported operator aten::unflatten encountered 6 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 6 time(s)\n",
      "Unsupported operator aten::gelu encountered 6 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5, base_model.encoder.layers.encoder_layer_5.dropout, base_model.encoder.layers.encoder_layer_5.ln_1, base_model.encoder.layers.encoder_layer_5.ln_2, base_model.encoder.layers.encoder_layer_5.mlp, base_model.encoder.layers.encoder_layer_5.mlp.0, base_model.encoder.layers.encoder_layer_5.mlp.1, base_model.encoder.layers.encoder_layer_5.mlp.2, base_model.encoder.layers.encoder_layer_5.mlp.3, base_model.encoder.layers.encoder_layer_5.mlp.4, base_model.encoder.layers.encoder_layer_5.self_attention, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4.0.self_attention.out_proj, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 29 time(s)\n",
      "Unsupported operator aten::add encountered 15 time(s)\n",
      "Unsupported operator aten::div encountered 7 time(s)\n",
      "Unsupported operator aten::unflatten encountered 7 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 7 time(s)\n",
      "Unsupported operator aten::gelu encountered 7 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6, base_model.encoder.layers.encoder_layer_6.dropout, base_model.encoder.layers.encoder_layer_6.ln_1, base_model.encoder.layers.encoder_layer_6.ln_2, base_model.encoder.layers.encoder_layer_6.mlp, base_model.encoder.layers.encoder_layer_6.mlp.0, base_model.encoder.layers.encoder_layer_6.mlp.1, base_model.encoder.layers.encoder_layer_6.mlp.2, base_model.encoder.layers.encoder_layer_6.mlp.3, base_model.encoder.layers.encoder_layer_6.mlp.4, base_model.encoder.layers.encoder_layer_6.self_attention, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5.0.self_attention.out_proj, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 33 time(s)\n",
      "Unsupported operator aten::add encountered 17 time(s)\n",
      "Unsupported operator aten::div encountered 8 time(s)\n",
      "Unsupported operator aten::unflatten encountered 8 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 8 time(s)\n",
      "Unsupported operator aten::gelu encountered 8 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7, base_model.encoder.layers.encoder_layer_7.dropout, base_model.encoder.layers.encoder_layer_7.ln_1, base_model.encoder.layers.encoder_layer_7.ln_2, base_model.encoder.layers.encoder_layer_7.mlp, base_model.encoder.layers.encoder_layer_7.mlp.0, base_model.encoder.layers.encoder_layer_7.mlp.1, base_model.encoder.layers.encoder_layer_7.mlp.2, base_model.encoder.layers.encoder_layer_7.mlp.3, base_model.encoder.layers.encoder_layer_7.mlp.4, base_model.encoder.layers.encoder_layer_7.self_attention, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6.0.self_attention.out_proj, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 37 time(s)\n",
      "Unsupported operator aten::add encountered 19 time(s)\n",
      "Unsupported operator aten::div encountered 9 time(s)\n",
      "Unsupported operator aten::unflatten encountered 9 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 9 time(s)\n",
      "Unsupported operator aten::gelu encountered 9 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8, base_model.encoder.layers.encoder_layer_8.dropout, base_model.encoder.layers.encoder_layer_8.ln_1, base_model.encoder.layers.encoder_layer_8.ln_2, base_model.encoder.layers.encoder_layer_8.mlp, base_model.encoder.layers.encoder_layer_8.mlp.0, base_model.encoder.layers.encoder_layer_8.mlp.1, base_model.encoder.layers.encoder_layer_8.mlp.2, base_model.encoder.layers.encoder_layer_8.mlp.3, base_model.encoder.layers.encoder_layer_8.mlp.4, base_model.encoder.layers.encoder_layer_8.self_attention, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7.0.self_attention.out_proj, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 41 time(s)\n",
      "Unsupported operator aten::add encountered 21 time(s)\n",
      "Unsupported operator aten::div encountered 10 time(s)\n",
      "Unsupported operator aten::unflatten encountered 10 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 10 time(s)\n",
      "Unsupported operator aten::gelu encountered 10 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9, base_model.encoder.layers.encoder_layer_9.dropout, base_model.encoder.layers.encoder_layer_9.ln_1, base_model.encoder.layers.encoder_layer_9.ln_2, base_model.encoder.layers.encoder_layer_9.mlp, base_model.encoder.layers.encoder_layer_9.mlp.0, base_model.encoder.layers.encoder_layer_9.mlp.1, base_model.encoder.layers.encoder_layer_9.mlp.2, base_model.encoder.layers.encoder_layer_9.mlp.3, base_model.encoder.layers.encoder_layer_9.mlp.4, base_model.encoder.layers.encoder_layer_9.self_attention, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8.0.self_attention.out_proj, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n",
      "Unsupported operator aten::mul encountered 45 time(s)\n",
      "Unsupported operator aten::add encountered 23 time(s)\n",
      "Unsupported operator aten::div encountered 11 time(s)\n",
      "Unsupported operator aten::unflatten encountered 11 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 11 time(s)\n",
      "Unsupported operator aten::gelu encountered 11 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10, base_model.encoder.layers.encoder_layer_10.dropout, base_model.encoder.layers.encoder_layer_10.ln_1, base_model.encoder.layers.encoder_layer_10.ln_2, base_model.encoder.layers.encoder_layer_10.mlp, base_model.encoder.layers.encoder_layer_10.mlp.0, base_model.encoder.layers.encoder_layer_10.mlp.1, base_model.encoder.layers.encoder_layer_10.mlp.2, base_model.encoder.layers.encoder_layer_10.mlp.3, base_model.encoder.layers.encoder_layer_10.mlp.4, base_model.encoder.layers.encoder_layer_10.self_attention, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11, base_model.encoder.layers.encoder_layer_11.dropout, base_model.encoder.layers.encoder_layer_11.ln_1, base_model.encoder.layers.encoder_layer_11.ln_2, base_model.encoder.layers.encoder_layer_11.mlp, base_model.encoder.layers.encoder_layer_11.mlp.0, base_model.encoder.layers.encoder_layer_11.mlp.1, base_model.encoder.layers.encoder_layer_11.mlp.2, base_model.encoder.layers.encoder_layer_11.mlp.3, base_model.encoder.layers.encoder_layer_11.mlp.4, base_model.encoder.layers.encoder_layer_11.self_attention, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, base_model.encoder.ln, base_model.heads, base_model.heads.head, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9.0.self_attention.out_proj\n",
      "Unsupported operator aten::mul encountered 49 time(s)\n",
      "Unsupported operator aten::add encountered 25 time(s)\n",
      "Unsupported operator aten::div encountered 12 time(s)\n",
      "Unsupported operator aten::unflatten encountered 12 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)\n",
      "Unsupported operator aten::gelu encountered 12 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "base_model.encoder.layers.encoder_layer_0.self_attention.out_proj, base_model.encoder.layers.encoder_layer_1.self_attention.out_proj, base_model.encoder.layers.encoder_layer_10.self_attention.out_proj, base_model.encoder.layers.encoder_layer_11.self_attention.out_proj, base_model.encoder.layers.encoder_layer_2.self_attention.out_proj, base_model.encoder.layers.encoder_layer_3.self_attention.out_proj, base_model.encoder.layers.encoder_layer_4.self_attention.out_proj, base_model.encoder.layers.encoder_layer_5.self_attention.out_proj, base_model.encoder.layers.encoder_layer_6.self_attention.out_proj, base_model.encoder.layers.encoder_layer_7.self_attention.out_proj, base_model.encoder.layers.encoder_layer_8.self_attention.out_proj, base_model.encoder.layers.encoder_layer_9.self_attention.out_proj, classifiers.0, classifiers.1, classifiers.2, classifiers.3, classifiers.4, classifiers.5, classifiers.6, classifiers.7, classifiers.8, classifiers.9, ees.0, ees.0.0, ees.0.0.dropout, ees.0.0.ln_1, ees.0.0.ln_2, ees.0.0.mlp, ees.0.0.mlp.0, ees.0.0.mlp.1, ees.0.0.mlp.2, ees.0.0.mlp.3, ees.0.0.mlp.4, ees.0.0.self_attention, ees.0.0.self_attention.out_proj, ees.0.1, ees.1, ees.1.0, ees.1.0.dropout, ees.1.0.ln_1, ees.1.0.ln_2, ees.1.0.mlp, ees.1.0.mlp.0, ees.1.0.mlp.1, ees.1.0.mlp.2, ees.1.0.mlp.3, ees.1.0.mlp.4, ees.1.0.self_attention, ees.1.0.self_attention.out_proj, ees.1.1, ees.2, ees.2.0, ees.2.0.dropout, ees.2.0.ln_1, ees.2.0.ln_2, ees.2.0.mlp, ees.2.0.mlp.0, ees.2.0.mlp.1, ees.2.0.mlp.2, ees.2.0.mlp.3, ees.2.0.mlp.4, ees.2.0.self_attention, ees.2.0.self_attention.out_proj, ees.2.1, ees.3, ees.3.0, ees.3.0.dropout, ees.3.0.ln_1, ees.3.0.ln_2, ees.3.0.mlp, ees.3.0.mlp.0, ees.3.0.mlp.1, ees.3.0.mlp.2, ees.3.0.mlp.3, ees.3.0.mlp.4, ees.3.0.self_attention, ees.3.0.self_attention.out_proj, ees.3.1, ees.4, ees.4.0, ees.4.0.dropout, ees.4.0.ln_1, ees.4.0.ln_2, ees.4.0.mlp, ees.4.0.mlp.0, ees.4.0.mlp.1, ees.4.0.mlp.2, ees.4.0.mlp.3, ees.4.0.mlp.4, ees.4.0.self_attention, ees.4.0.self_attention.out_proj, ees.4.1, ees.5, ees.5.0, ees.5.0.dropout, ees.5.0.ln_1, ees.5.0.ln_2, ees.5.0.mlp, ees.5.0.mlp.0, ees.5.0.mlp.1, ees.5.0.mlp.2, ees.5.0.mlp.3, ees.5.0.mlp.4, ees.5.0.self_attention, ees.5.0.self_attention.out_proj, ees.5.1, ees.6, ees.6.0, ees.6.0.dropout, ees.6.0.ln_1, ees.6.0.ln_2, ees.6.0.mlp, ees.6.0.mlp.0, ees.6.0.mlp.1, ees.6.0.mlp.2, ees.6.0.mlp.3, ees.6.0.mlp.4, ees.6.0.self_attention, ees.6.0.self_attention.out_proj, ees.6.1, ees.7, ees.7.0, ees.7.0.dropout, ees.7.0.ln_1, ees.7.0.ln_2, ees.7.0.mlp, ees.7.0.mlp.0, ees.7.0.mlp.1, ees.7.0.mlp.2, ees.7.0.mlp.3, ees.7.0.mlp.4, ees.7.0.self_attention, ees.7.0.self_attention.out_proj, ees.7.1, ees.8, ees.8.0, ees.8.0.dropout, ees.8.0.ln_1, ees.8.0.ln_2, ees.8.0.mlp, ees.8.0.mlp.0, ees.8.0.mlp.1, ees.8.0.mlp.2, ees.8.0.mlp.3, ees.8.0.mlp.4, ees.8.0.self_attention, ees.8.0.self_attention.out_proj, ees.8.1, ees.9, ees.9.0, ees.9.0.dropout, ees.9.0.ln_1, ees.9.0.ln_2, ees.9.0.mlp, ees.9.0.mlp.0, ees.9.0.mlp.1, ees.9.0.mlp.2, ees.9.0.mlp.3, ees.9.0.mlp.4, ees.9.0.self_attention, ees.9.0.self_attention.out_proj, ees.9.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2908843776, 4304700672, 5700557568, 7096414464, 8492271360, 9888128256, 11283985152, 12679842048, 14075698944, 15471555840, 16867412736\n"
     ]
    }
   ],
   "source": [
    "'''from torchinfo import summary    #wrong result in multi-head attention module in vit\n",
    "tmp=[]\n",
    "for i in range(exit_num):\n",
    "    new_model.set_each_ee_test_mode(i)\n",
    "    #summary(new_model,input_size= (1, 3, IMG_SIZE, IMG_SIZE))\n",
    "    tmp.append(summary(new_model,input_size= (1, 3, IMG_SIZE, IMG_SIZE)).total_mult_adds)\n",
    "tmp''' \n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "tmp = []\n",
    "for i in range(exit_num):\n",
    "    new_model.set_each_ee_test_mode(i)\n",
    "    x = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "    flops = FlopCountAnalysis(new_model, x)\n",
    "    tmp.append(flops.total())\n",
    "print(', '.join(map(str, tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7801511784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet101 FLOPs: 16866721536\n",
    "# 7799667684(resnet101) VS 16866721536(ViT-b/16)\n",
    "from torchinfo import summary\n",
    "pretrained_resnet101 = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "pretrained_resnet101.fc = nn.Linear(pretrained_resnet101.fc.in_features, dataset_outdim[data_choice])\n",
    "summary(pretrained_resnet101,input_size= (1, 3, IMG_SIZE, IMG_SIZE)).total_mult_adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.24923290770295 %\n"
     ]
    }
   ],
   "source": [
    "print(16866721536 / 7799667684 * 100,'%') #ViT-b/16의 flops가 resnet101의 216.24%이다.. 즉 2배이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.80294075046498 %\n"
     ]
    }
   ],
   "source": [
    "# 만약 앙상블을 한다면 총 연산량은 단일출구에 비해 1.8배가 될 것이다.\n",
    "print(30832862976 / 16866721536 * 100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
